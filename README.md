# ğŸ“š Study Buddy â€“ Ask Questions on Your Notes

**Study Buddy** is a smart, AI-powered note assistant that allows you to upload your study materials (PDF/DOCX) and ask questions about them. It uses local LLMs with Retrieval-Augmented Generation (RAG) to provide accurate, context-aware answers directly from your notes.

---

## ğŸš€ Features

- ğŸ“„ **File Upload** â€“ Supports PDF and DOCX study notes
- ğŸ” **RAG Pipeline** â€“ Combines semantic search with local LLMs
- ğŸ§  **Embeddings** â€“ Uses `sentence-transformers` (MiniLM) to generate vector embeddings
- ğŸ” **Vector Search** â€“ Powered by FAISS for fast similarity search
- ğŸ¤– **Local LLM** â€“ Uses Ollama (e.g. Mistral model) for generating context-based answers
- ğŸŒ **Frontend** â€“ HTML + JavaScript interface for question submission and file upload

---

## ğŸ› ï¸ Tech Stack

| Part                 | Technology                                | Purpose                                          |
| -------------------- | ------------------------------------------| ------------------------------------------------ |
| âœ… Backend Framework | **FastAPI**                               | To build the API endpoints                       |
| ğŸ“„ File Processing  | **PyPDF2, python-docx**                   | To read text from PDF and DOCX                   |
| ğŸ§  Embeddings       | **sentence-transformers (MiniLM)**        | To convert text chunks into vectors              |
| ğŸ” Vector Search    | **FAISS**                                 | To search similar chunks using vector similarity |
| ğŸ’¾ Data Storage     | **Pickle**                                | To save/load the index                           |
| ğŸ¤– LLM              | **Ollama (e.g. mistral model)**           | To generate answers based on context             |
| ğŸŒ Frontend         | **HTML + JavaScript (from `index.html`)** | For uploading files and asking questions         |

---

## ğŸ§‘â€ğŸ’» How It Works

1. **Upload Study Material** â€“ Upload a PDF or DOCX file through the web interface.
2. **Text Chunking** â€“ The file is split into manageable text chunks.
3. **Vector Embedding** â€“ Each chunk is converted to a vector using sentence-transformers.
4. **Vector Indexing** â€“ Vectors are stored using FAISS for similarity search.
5. **RAG** â€“ When a user asks a question, relevant chunks are retrieved and passed to the local LLM via Ollama to generate a response.

---

## ğŸ“¦ Installation

### Prerequisites

- Python 3.8+
- Ollama (installed and running locally)
- Mistral model pulled in Ollama:  
  ```bash
  ollama pull mistral

**#Setup**
# Clone the repo
git clone https://github.com/Himans30/Study-Buddy-Ask-Questions-on-Your-Notes.git
cd Study-Buddy-Ask-Questions-on-Your-Notes

# Install dependencies
pip install -r requirements.txt

# Run FastAPI backend
uvicorn app:app --reload

